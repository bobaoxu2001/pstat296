TR26_21 <- as.data.frame(sapply(TR26_21, as.numeric))
TR26_21 <- TR26_21 %>%
mutate(observed_month = as.Date(observed_month,origin = "1899-12-30"))
TR26_21
Govt_20_Yield <- TR26_21[,c(1,8)]
Govt_20_Yield
Govt_20_Yield$yield_percentage <- round(Govt_20_Yield$lt_govt_yield_20_year*100, digits = 3)
percentage <- ts(Govt_20_Yield$yield_percentage[1:1161], frequency = 12, start = c(1926,1,1))
ts.plot(percentage, type="l")
summary(Govt_20_Yield$yield_percentage)
# Since there is a big difference between the time before index 769 (1990.01) and after that
# So we choose to research in the data after index 709
# Divide it into train and test for nearly 90% and 10%
train <- Govt_20_Yield$yield_percentage[769:1149]
test <- Govt_20_Yield$yield_percentage[1153:1161]
#train set contains data points from 1990.01 to 2021.12, 381 points totally
#test set contains data points from 2022.1 and 2022.9, 9 points totally
par(mfrow=c(3, 1))
data <- ts(Govt_20_Yield$yield_percentage[769:1161], frequency = 12, start = c(1990,1,1))
c_train <- ts(train, frequency = 12, start = c(1990,1,1))
c_test <-ts(test,frequency = 12,start = c(2022,1))
ts.plot(data)
ts.plot(c_train)
ts.plot(c_test)
plot.ts(c_train, main="SBBI Interest training data")
fit <- lm(c_train ~ as.numeric(1:length(c_train)))
abline(h=mean(c_train), col="blue")
hist(c_train, main="Histogram of c_train",xlab="date",freq = F)
m <- mean(c_train)
std <- sqrt(var(c_train))
curve(dnorm(x, m, std), col="red", add=TRUE,yaxt = "n")
acf(c_train, lag.max = 40, main = "")
# Box-Cox transformation:
t <- 1:length(c_train)
bcTransform <- boxcox(c_train ~ t, plotit=TRUE)
lambda <- bcTransform$x[which.max(bcTransform$y)]
c_train.bc = (1/lambda)*(c_train^lambda-1)
lambda
plot(c_train.bc)
par(mfrow=c(1,2))
hist(c_train, main="Histogram of c_train",xlab="date")
hist(c_train.bc, main="Histogram of c_train.bc",xlab="date")
# Plot and compare the two:
par(mfrow=c(2,3))
plot.ts(c_train,xlab = "", main = "")
hist(c_train, col = "light blue", xlab = "", main = "")
qqnorm(c_train, main = "", xlab = "")
qqline(c_train, col = "red")
plot.ts(c_train.bc,xlab = "", main = "")
hist(c_train.bc, col = "light blue", xlab = "", main = "")
qqnorm(c_train.bc, main = "", xlab = "")
qqline(c_train.bc, col = "red")
decomp <- decompose(c_train.bc)
plot(decomp)
# Deseasonalize and detrend:
c_train.bc.12 <- diff(c_train.bc, 12)
c_train.bc.12.1 <- diff(c_train.bc.12, 1)
c_train.bc.1 <- diff(c_train.bc, 1)
c_train.bc.1.12 <- diff(c_train.bc.1, 12)
var(c_train.bc)
var(c_train.bc.12);
var(c_train.bc.12.1);
var(c_train.bc.1);
var(c_train.bc.1.12)
hist(c_train.bc.1, col = "light blue", xlab = "", main = "")
# Plot it for De-seasonlized Time Series :
par(mfrow=c(1, 1))
ts.plot(c_train.bc.1, main="De-seasonlized Time Series",
ylab=expression(nabla[1]~Y[t]))
abline(h=mean(c_train.bc.1), lty=2)
acf(c_train.bc.1, lag.max=120, main="ACF")
pacf(c_train.bc.1, lag.max=120, main="PACF")
library(forecast)
auto.arima(c_train.bc.1,ic = c("aicc"),seasonal = F,stepwise = F)
arima(c_train.bc.1,order=c(2,1,2), method="ML")
AICc(arima(c_train.bc.1, order=c(0,0,2), method="ML"))
arima(c_train.bc.1, order=c(0,0,2),fixed=c(0,NA,NA), method="ML")
AICc(arima(c_train.bc.1, order=c(0,0,2),fixed=c(0,NA,NA), method="ML"))
polyroot(c(1, 0, -0.1448))
# Plot the residuals
fit1 <- arima(c_train, order = c(0,0,2),
seasonal = list(order = c(0,0,2), period = 12), method = "ML")
res1 <- residuals(fit1)
plot.ts(res1, xlab = "")
abline(h=mean(res1),col = "blue")
# Plot the histogram, Q-Q normal plot of the residual par(mfrow=c(1,2))
hist(res1, density = 20, breaks = 20,
col = "blue", xlab = "", prob = TRUE, main = "")
m1 <- mean(res1)
std1 <- sqrt(var(res1))
curve(dnorm(x,m1,std1),add = TRUE)
qqnorm(res1,main = "", xlab = "")
qqline(res1, col = "blue")
# Plot the ACF and PACF of the residual
par(mfrow=c(1,2))
acf(res1,lag.max=60, main = "")
pacf(res1,lag.max=60, main = "")
# Perform test on Model 1's residual
shapiro.test(res1)
Box.test(res1,lag = 20, type = c("Box-Pierce"),fitdf = 1)
Box.test(res1,lag = 20, type = c("Ljung-Box"),fitdf = 1)
Box.test(res1^2,lag = 20, type = c("Ljung-Box"),fitdf = 0)
ar(res1,aic=TRUE,order.max=NULL, mehod = c("yule-walker"))
fit.1<-arima(c_train, order = c(0,0,2), fixed=c(0,NA,NA), method = "ML")
# Create confidence interval
pred.tr <- predict(fit.1, n.ahead = 12)
U1 = pred.tr$pred + 2*pred.tr$se
L1 = pred.tr$pred - 2*pred.tr$se
# Forecast on original data
plot.ts(c_train, xlim = c(1990,2022), ylim = c(1,10))
lines(U1, col = "blue", lty = "dashed")
lines(L1, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
legend("bottomright", c("Prediction","95% C.I."),
fill = c("red", "blue"), cex = 1.25) # Zoom in graph
plot.ts(c_train, xlim = c(1990,2022), ylim = c(1,max(U1)))
lines(U1, col = "blue", lty = "dashed")
lines(L1, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
legend("bottomright", c("Prediction","95% C.I."),
fill = c("red", "blue"), cex = 1.25) # Forecast with test dataset
plot.ts(milk, xlim = c(1990,2022), ylim = c(1,max(U1)))
lines(U1, col = "blue", lty = "dashed")
lines(L1, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
points(c_test,col = "slategrey", pch = 20)
legend("bottomright", c("Prediction","95% C.I.","c_test"),
fill = c("red", "blue","slategrey"), cex = 1.25)
arima(c_train.bc, order = c(2,1,2), method = "ML")
arima(c_train.bc, order = c(2,1,2),fixed=c(NA,0,NA,0), method = "ML")
AICc(arima(c_train.bc.1, order=c(2,1,2), method="ML"))
AICc(arima(c_train.bc, order = c(2,1,2),fixed=c(NA,0,NA,0), method = "ML"))
# Plot the residuals
fit2 <- arima(c_train.bc, order = c(2,1,2),fixed=c(NA,0,NA,0), method = "ML")
res2 <- residuals(fit2)
plot.ts(res2, xlab = "")
abline(h=mean(res2),col = "blue")
# Plot the histogram, Q-Q normal plot of the residual par(mfrow=c(1,2))
hist(res2, density = 20, breaks = 20,
col2 = "blue", xlab = "", prob = TRUE, main = "")
m2 <- mean(res2)
std2 <- sqrt(var(res2))
curve(dnorm(x,m2,std2),add = TRUE)
qqnorm(res2,main = "", xlab = "")
qqline(res2, col = "blue")
# Plot the ACF and PACF of the residual
par(mfrow=c(1,2))
acf(res2,lag.max=60, main = "")
pacf(res2,lag.max=60, main = "")
# Perform test on Model 1's residual
shapiro.test(res2)
Box.test(res2,lag = 20, type = c("Box-Pierce"),fitdf = 2)
Box.test(res2,lag = 20, type = c("Ljung-Box"),fitdf = 2)
Box.test(res2^2,lag = 20, type = c("Ljung-Box"),fitdf = 0)
ar(res1,aic=TRUE,order.max=NULL, mehod = c("yule-walker"))
fit.1<-arima(c_train, order = c(0,1,1),
seasonal = list(order = c(0,1,4), period = 12), method = "ML")
# Create confidence interval
pred.tr <- predict(fit.1, n.ahead = 12)
U = pred.tr$pred + 2*pred.tr$se
L = pred.tr$pred - 2*pred.tr$se
# Forecast on original data
plot.ts(c_train, xlim = c(1962,1976), ylim = c(500,1000))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
legend("bottomright", c("Prediction","95% C.I."),
fill = c("red", "blue"), cex = 1.25) # Zoom in graph
plot.ts(c_train, xlim = c(1973,1976), ylim = c(700,max(U)))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
legend("bottomright", c("Prediction","95% C.I."),
fill = c("red", "blue"), cex = 1.25) # Forecast with test dataset
plot.ts(milk, xlim = c(1973,1976), ylim = c(700,max(U)))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
points(c_test,col = "slategrey", pch = 20)
legend("bottomright", c("Prediction","95% C.I.","c_test"),
fill = c("red", "blue","slategrey"), cex = 1.25)
# Forecast with test dataset
plot.ts(data, xlim = c(2010,2025), ylim = c(0,7))
lines(U.tr, col = "blue", lty = "dashed")
library(forecast)
auto.arima(c_train,ic = c("aicc"),seasonal = F,stepwise = F)
library(forecast)
auto.arima(c_train.bc.1,ic = c("aicc"),seasonal = F,stepwise = F)
arima(c_train.bc, order = c(2,1,2), method = "ML")
arima(c_train.bc, order = c(2,1,2), method = "ML")
arima(c_train.bc, order = c(2,1,2),fixed=c(NA,0,NA,0), method = "ML")
library(tsdl)
library(forecast)
library(tidyverse)
library(astsa)
library(MASS)
library(ggplot2)
library(readxl)
library(ggfortify)
library(forecast)
library(GeneCycle)
library(qpcR)
# require(TSA)
#source("plot.roots.R")
length(tsdl[[203]])
attr(tsdl[[203]],"subject")
attr(tsdl[[203]],"source")
attr(tsdl[[203]],"description")
milk <- tsdl[[203]]
plot.ts(milk)
str(milk)
# Set up training and testing group
# c_train totally 156 points, c_test totally 12 points
c_train <- ts(milk[1:156],start = c(1962,1),frequency = 12)
c_test <-ts(milk[157:168],start = c(1975,1),frequency = 12)
# Show histogram and acf plot of c_train
par(mfrow=c(1,2))
hist(c_train, col = "light blue",main = "")
acf(c_train, lag.max = 40, main = "")
# Perform box-cox transformation on c_train
bcTransform <- boxcox(c_train~as.numeric(1:length(c_train)))
lambda = bcTransform$x[which(bcTransform$y == max(bcTransform$y))]
milk.bc = (1/lambda)*(c_train^lambda-1)
lambda
# Perform log transformation on c_train
milk.log <- log(c_train)
plot.ts(milk.log)
# Compare c_train and milk.bc
par(mfrow=c(2,3))
plot.ts(c_train,xlab = "", main = "")
hist(c_train, col = "light blue", xlab = "", main = "")
qqnorm(c_train, main = "", xlab = "")
qqline(c_train, col = "red")
plot.ts(milk.log,xlab = "", main = "")
hist(milk.log, col = "light blue", xlab = "", main = "")
qqnorm(milk.log, main = "", xlab = "")
qqline(milk.log, col = "red")
y <- ts(as.ts(milk.log), frequency = 12)
decomp <- decompose(y)
plot(decomp)
# ln(Ut) differenced at lag 12
var(milk.log)
milk.log_12 <- diff(milk.log, lag=12)
var(milk.log_12)
# ln(Ut) differenced at lag 12 and then lag 1
milk.log_12_1 <- diff(milk.log_12, lag=1)
var(milk.log_12_1)
# ln(Ut) differenced at lag 12, then lag 1 and then lag 1
milk.log_12_1_1 <- diff(milk.log_12_1, lag=1)
var(milk.log_12_1_1)
# To check number differencing par(mfrow=c(1,2))
plot.ts(milk, main = "")
plot.ts(milk.log_12, main = "Ln(U_t) differenced at lag 12")
abline(h=mean(milk.log_12), col = "blue")
fit <- lm(milk.log_12 ~ as.numeric(1:length(milk.log_12)))
#abline(fit, col="red")
plot.ts(milk.log_12_1, main = "Ln(U_t) differenced at lag 12, at lag 1")
abline(h=mean(milk.log_12_1), col = "blue")
fit2 <- lm(milk.log_12_1 ~ as.numeric(1:length(milk.log_12_1)))
#abline(fit2, col="red")
# Compare the ACF and PACF of milk.log, milk.log_12, and milk.log_12_1
par(mfrow=c(2,3))
acf(milk.log, lag.max = 40, main = expression(U[t]))
acf(milk.log_12, lag.max = 40, main = expression(nabla[12]~~U[t]))
acf(milk.log_12_1, lag.max = 40, main =expression(nabla[1]~nabla[12]~~U[t]))
pacf(milk.log, lag.max = 40, main = "")
pacf(milk.log_12, lag.max = 40, main = "")
pacf(milk.log_12_1, lag.max = 40, main = "")
# Compare the histgram of milk.log, milk.log_12, and milk.log_12_1
hist(milk.log, density=20,breaks=20, col="blue", xlab="", prob=TRUE)
hist(milk.log_12, density=20,breaks=20, col="blue", xlab="", prob=TRUE)
hist(milk.log_12_1, density=20,breaks=20, col="blue", xlab="", prob=TRUE)
# Decide the proper p,d,q, P,D,Q from the acf and pacf plots
acf(milk.log_12_1, lag.max = 120, main="ACF of the log(U_t)_12_1")
pacf(milk.log_12_1, lag.max = 120, main="ACF of the log(U_t)_12_1")
# Calculate the AICc of possible models
# Error in optim(init[mask], armafn, method = optim.method, hessian = TRUE, non-finite finite-difference value [2]. It appears due to not enough data
a <- AICc(arima(milk.log, order = c(0,1,1), seasonal = list(order = c(0,1,4), period = 12),method = "ML"))
a
arima(milk.log, order = c(0,1,1), seasonal = list(order = c(0,1,4), period = 12),method = "ML")
arima(milk.log, order=c(0,1,1), seasonal = list(order = c(0,1,4), period = 12), fixed = c(NA,NA,0,0,NA), method="ML")
# Calculate the AICc of possible models
b <- AICc(arima(milk.log, order=c(0,1,1), seasonal = list(order = c(0,1,4), period = 12), fixed = c(NA,NA,0,0,NA), method="ML"))
b
arima(milk.log, order=c(0,1,1), seasonal = list(order = c(0,1,4), period = 12), fixed = c(NA,NA,0,0,NA), method="ML")
polyroot(c(1, -0.1729))
#To check invertibility of MA part of model A:
install.packages("UnitCircle")
library(UnitCircle)
par(mfrow=c(1,2))
uc.check(pol_ = c(1,-0.6771,0,0,0.3054), plot_output = TRUE,print_output = F) # Seasonal MA Part
uc.check(pol_ = c(1,-0.1729), plot_output = TRUE,print_output = F) # Non-Seasonal MA Part
# Plot the residuals
fit1 <- arima(milk.log, order = c(0,1,1),seasonal = list(order = c(0,1,4), period = 12), method = "ML")
res1 <- residuals(fit1)
plot.ts(res1, xlab = "")
abline(h=mean(res1),col = "blue")
# Plot the histogram, Q-Q normal plot of the residual par(mfrow=c(1,2))
hist(res1, density = 20, breaks = 20,
col = "blue", xlab = "", prob = TRUE, main = "")
m1 <- mean(res1)
std1 <- sqrt(var(res1))
curve(dnorm(x,m1,std1),add = TRUE)
qqnorm(res1,main = "", xlab = "")
qqline(res1, col = "blue")
# Plot the ACF and PACF of the residual
par(mfrow=c(1,2))
acf(res1,lag.max=60, main = "")
pacf(res1,lag.max=60, main = "")
# Perform test on Model 1's residual
# sqrt(156) is 12.49, so we can choose lag = 12
shapiro.test(res1)
Box.test(res1,lag = 12, type = c("Box-Pierce"),fitdf = 3) # 3 coefficients
Box.test(res1,lag = 12, type = c("Ljung-Box"),fitdf = 3) # 3 coefficients
Box.test(res1^2,lag = 12, type = c("Ljung-Box"),fitdf = 0)
ar(res1,aic=TRUE,order.max=NULL, method = c("yule-walker"))
require(TSA)
# Graph the periodogram of Model 1 residual
periodogram(res1)
abline(h = 0)
# Perform Kolmogorov-Smirnov Test on Model 1 residual
cpgram(res1, main = 'Kolmogorov-Smirnov Test')
# Perform fisher test on Model 1 residual
fisher.g.test(res1)
fit.1<-arima(c_train, order = c(0,1,1),
seasonal = list(order = c(0,1,4), period = 12), method = "ML")
# Create confidence interval
pred.tr <- predict(fit.1, n.ahead = 12)
U = pred.tr$pred + 2*pred.tr$se
L = pred.tr$pred - 2*pred.tr$se
# Forecast on original data
plot.ts(c_train, xlim = c(1962,1976), ylim = c(500,1000))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
legend("bottomright", c("Prediction","95% C.I."),
fill = c("red", "blue"), cex = 1.25) # Zoom in graph
plot.ts(c_train, xlim = c(1973,1976), ylim = c(700,max(U)))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
legend("bottomright", c("Prediction","95% C.I."),
fill = c("red", "blue"), cex = 1.25) # Forecast with test dataset
plot.ts(milk, xlim = c(1973,1976), ylim = c(700,max(U)))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
points(c_test,col = "slategrey", pch = 20)
legend("bottomright", c("Prediction","95% C.I.","c_test"),
fill = c("red", "blue","slategrey"), cex = 1.25)
AICc(arima(c_train.bc, order = c(2,1,2),fixed=c(NA,NA,NA,0), method = "ML"))
AICc(arima(c_train.bc, order=c(2,1,2), method="ML"))
# Plot the residuals
fit2 <- arima(c_train.bc, order = c(2,1,2),fixed=c(NA,NA,NA,0), method = "ML")
res2 <- residuals(fit2)
plot.ts(res2, xlab = "")
abline(h=mean(res2),col = "blue")
# Plot the histogram, Q-Q normal plot of the residual par(mfrow=c(1,2))
hist(res2, density = 20, breaks = 20,
col2 = "blue", xlab = "", prob = TRUE, main = "")
m2 <- mean(res2)
std2 <- sqrt(var(res2))
curve(dnorm(x,m2,std2),add = TRUE)
qqnorm(res2,main = "", xlab = "")
qqline(res2, col = "blue")
# Plot the ACF and PACF of the residual
par(mfrow=c(1,2))
acf(res2,lag.max=60, main = "")
pacf(res2,lag.max=60, main = "")
# Perform test on Model 1's residual
shapiro.test(res2)
Box.test(res2,lag = 20, type = c("Box-Pierce"),fitdf = 2)
Box.test(res2,lag = 20, type = c("Ljung-Box"),fitdf = 2)
Box.test(res2^2,lag = 20, type = c("Ljung-Box"),fitdf = 0)
ar(res1,aic=TRUE,order.max=NULL, mehod = c("yule-walker"))
# Perform test on Model 1's residual
shapiro.test(res2)
Box.test(res2,lag = 20, type = c("Box-Pierce"),fitdf = 3)
Box.test(res2,lag = 20, type = c("Ljung-Box"),fitdf = 3)
Box.test(res2^2,lag = 20, type = c("Ljung-Box"),fitdf = 0)
ar(res1,aic=TRUE,order.max=NULL, mehod = c("yule-walker"))
# Perform test on Model 1's residual
shapiro.test(res2)
Box.test(res2,lag = 20, type = c("Box-Pierce"),fitdf = 3)
Box.test(res2,lag = 20, type = c("Ljung-Box"),fitdf = 3)
Box.test(res2^2,lag = 20, type = c("Ljung-Box"),fitdf = 0)
ar(res1,aic=TRUE,order.max=NULL, mehod = c("yule-walker"))
fit.1<-arima(c_train, order = c(2,1,2), method = "ML")
# Create confidence interval
pred.tr <- predict(fit.1, n.ahead = 12)
U = pred.tr$pred + 2*pred.tr$se
L = pred.tr$pred - 2*pred.tr$se
# Forecast on original data
plot.ts(c_train, xlim = c(1990,2022), ylim = c(2,10))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
legend("bottomright", c("Prediction","95% C.I."),
fill = c("red", "blue"), cex = 1.25) # Zoom in graph
plot.ts(c_train, xlim = c(1990,2022), ylim = c(2,10))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
legend("bottomright", c("Prediction","95% C.I."),
fill = c("red", "blue"), cex = 1.25) # Forecast with test dataset
plot.ts(milk, xlim = c(1990,2022), ylim = c(2,10))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
points(c_test,col = "slategrey", pch = 20)
legend("bottomright", c("Prediction","95% C.I.","c_test"),
fill = c("red", "blue","slategrey"), cex = 1.25)
fit.1<-arima(c_train, order = c(2,1,2), method = "ML")
# Create confidence interval
pred.tr <- predict(fit.1, n.ahead = 12)
U = pred.tr$pred + 2*pred.tr$se
L = pred.tr$pred - 2*pred.tr$se
# Forecast on original data
plot.ts(c_train, xlim = c(1990,2022))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
legend("bottomright", c("Prediction","95% C.I."),
fill = c("red", "blue"), cex = 1.25) # Zoom in graph
plot.ts(c_train, xlim = c(1990,2022))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
legend("bottomright", c("Prediction","95% C.I."),
fill = c("red", "blue"), cex = 1.25) # Forecast with test dataset
plot.ts(milk, xlim = c(1990,2022))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
points(c_test,col = "slategrey", pch = 20)
legend("bottomright", c("Prediction","95% C.I.","c_test"),
fill = c("red", "blue","slategrey"), cex = 1.25)
fit.1<-arima(c_train, order = c(2,1,2),fixed=c(NA,NA,NA,0), method = "ML")
# Create confidence interval
pred.tr <- predict(fit.1, n.ahead = 12)
U = pred.tr$pred + 2*pred.tr$se
L = pred.tr$pred - 2*pred.tr$se
# Forecast on original data
plot.ts(c_train, xlim = c(1990,2022), ylim = c(2,10))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
legend("bottomright", c("Prediction","95% C.I."),
fill = c("red", "blue"), cex = 1.25) # Zoom in graph
plot.ts(c_train, xlim = c(1990,2022))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
legend("bottomright", c("Prediction","95% C.I."),
fill = c("red", "blue"), cex = 1.25) # Forecast with test dataset
plot.ts(milk, xlim = c(1990,2022))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
points(c_test,col = "slategrey", pch = 20)
legend("bottomright", c("Prediction","95% C.I.","c_test"),
fill = c("red", "blue","slategrey"), cex = 1.25)
fit.1<-arima(c_train, order = c(2,1,2),fixed=c(NA,NA,NA,0), method = "ML")
# Create confidence interval
pred.tr <- predict(fit.1, n.ahead = 12)
U = pred.tr$pred + 2*pred.tr$se
L = pred.tr$pred - 2*pred.tr$se
# Forecast on original data
plot.ts(c_train, xlim = c(1990,2022), ylim = c(1,10))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
legend("bottomright", c("Prediction","95% C.I."),
fill = c("red", "blue"), cex = 1.25) # Zoom in graph
plot.ts(c_train, xlim = c(1990,2022))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
legend("bottomright", c("Prediction","95% C.I."),
fill = c("red", "blue"), cex = 1.25) # Forecast with test dataset
plot.ts(milk, xlim = c(1990,2022))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
points(c_test,col = "slategrey", pch = 20)
legend("bottomright", c("Prediction","95% C.I.","c_test"),
fill = c("red", "blue","slategrey"), cex = 1.25)
fit.2<-arima(c_train, order = c(2,1,2),fixed=c(NA,NA,NA,0), method = "ML")
# Create confidence interval
pred.tr <- predict(fit.2, n.ahead = 12)
U = pred.tr$pred + 2*pred.tr$se
L = pred.tr$pred - 2*pred.tr$se
# Forecast on original data
plot.ts(c_train, xlim = c(1990,2022), ylim = c(1,10))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
legend("bottomright", c("Prediction","95% C.I."),
fill = c("red", "blue"), cex = 1.25) # Zoom in graph
plot.ts(c_train, xlim = c(1990,2022))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
legend("bottomright", c("Prediction","95% C.I."),
fill = c("red", "blue"), cex = 1.25) # Forecast with test dataset
plot.ts(milk, xlim = c(1990,2022))
lines(U, col = "blue", lty = "dashed")
lines(L, col = "blue", lty = "dashed")
points(pred.tr$pred,col = "red", pch = 1)
points(c_test,col = "slategrey", pch = 20)
legend("bottomright", c("Prediction","95% C.I.","c_test"),
fill = c("red", "blue","slategrey"), cex = 1.25)
